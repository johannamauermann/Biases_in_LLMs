{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR7jmRPbjcF_"
      },
      "source": [
        "# Prompting Notebook\n",
        "\n",
        "This notebook illustrates the general principles of our prompting approach by providing exemplary prompts in French and English, along with the corresponding API call functions for different LLMs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts"
      ],
      "metadata": {
        "id": "b_WwJr1y3b3F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAg4BsExjYSf"
      },
      "outputs": [],
      "source": [
        "system_prompt_english =\"\"\"# System Instructions\n",
        "You are an expert text analyst and information retrieval specialist and hate summarization as well as enumerations.\n",
        "Your task is to carefully analyze given texts and extract complete articles that contain specific themes. You never change original texts.\n",
        "\n",
        "Classify as relevant if the text contains:\n",
        "- Primary earthquake terminology from the 19th and 20th century\n",
        "- Official earthquake reports\n",
        "- geology and seismology\n",
        "- Impact descriptions\n",
        "- Solution description\n",
        "- Technical description\n",
        "- Aid\n",
        "- Honorations\n",
        "- Political discussion and opinions on earthquake\n",
        "- Stories from victims and refugees\n",
        "- reportings on refugees and victims\n",
        "- Live of victims\n",
        "- historical references\n",
        "- comparisons\n",
        "\n",
        "Not relevant are ads and theater or movie announcements.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OEPpc6hjYKj"
      },
      "outputs": [],
      "source": [
        "user_prompt_english = \"\"\"\n",
        "Please follow these specifications:\n",
        "1. Definition of an article: An article is a semantic unit in the text, clearly distinguished from preceding and following content (e.g., through its own headline).\n",
        "2. Relevance criteria: An article is relevant if it has the Messina earthquake of December 1908 or its consequences are a topic. Relevant articles, next to the reports on the earthquake, can include:\n",
        "• Effects on the population (e.g., health crises, forced relocations, relief efforts and donations)\n",
        "• Aftershocks and consequences\n",
        "• Political and economic developments related to the earthquake\n",
        "3. Response format:\n",
        "• If one or more relevant articles are found, structure your response using XML tags as shown in the following example, using the tags article, verification, and human_verification_needed (True or False): <article>complete extracted article content</article><verification>Is unit coherent? Is topic present? Is article complete? All articles found?</verification><human_verification_needed>False</human_verification_needed>\n",
        "• Return all relevant articles in their original form, without additions, omissions, corrections, or comments.\n",
        "• If no relevant articles about the Messina earthquake are found (e.g., if it concerns another earthquake), no special structuring is needed; simply return \"No relevant article found.\" without further explanations.\n",
        "4. Notes on segmentation:\n",
        "• Ensure that articles spread across multiple paragraphs are treated as a single unit.\n",
        "• Never truncate for brevity\n",
        "5. Human verification needed:\n",
        "• Can have the values \"True\" or \"False\"\n",
        "• False: If you believe you have correctly segmented the article and assessed its relevance.\n",
        "• True: If you are unsure whether you have captured the complete content of the article as contained in the newspaper document or whether it is relevant.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "user_prompt_french = \"\"\"\n",
        "Veuillez prendre en compte ces spécifications :\n",
        "\n",
        "1. Définition d'un article : Un article est une unité sémantique dans le texte qui se distingue clairement du contenu précédent et suivant (par exemple par son propre titre).\n",
        "\n",
        "2. Critères de pertinence : Un article est pertinent s'il traite du tremblement de terre de Messine de décembre 1908 ou de ses conséquences. Les conséquences pertinentes peuvent inclure :\n",
        "• Impacts sur la population (par exemple, crises sanitaires, déplacements forcés, mesures d'aide et dons)\n",
        "• Répliques sismiques et leurs effets\n",
        "• Développements politiques et économiques liés au tremblement de terre\n",
        "\n",
        "3. Format de réponse :\n",
        "• Si un ou plusieurs articles pertinents sont trouvés, structurez votre réponse en utilisant des balises XML comme dans l'exemple suivant, en utilisant les balises article, verification et human_verification_needed (True ou False) : <article>contenu intégral de l'article extrait</article><verification>L'unité est-elle cohérente ? Le sujet est-il présent ? L'article est-il complet ? Tous les articles ont-ils été trouvés ?</verification><human_verification_needed>False</human_verification_needed>\n",
        "• Retournez tous les articles pertinents dans leur forme originale, sans ajouts, omissions, corrections ou commentaires.\n",
        "• Si aucun article pertinent sur le tremblement de terre de Messine n'est trouvé (par exemple s'il s'agit d'un autre tremblement de terre), aucune structuration particulière n'est requise ; retournez simplement \"Aucun article pertinent trouvé.\" sans autres explications.\n",
        "\n",
        "4. Notes sur la segmentation :\n",
        "• Assurez-vous que les articles répartis sur plusieurs paragraphes sont traités comme une seule unité.\n",
        "\n",
        "5. Nécessité de vérification humaine :\n",
        "• Peut avoir les valeurs \"True\" ou \"False\"\n",
        "• False : Si vous pensez avoir correctement segmenté l'article et bien évalué sa pertinence.\n",
        "• True : Si vous n'êtes pas certain d'avoir capturé le contenu complet de l'article tel qu'il figure dans le document de journal ou s'il est pertinent.\n",
        "\n",
        "Voici le document de journal :\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MH-nFmCMjX_C"
      },
      "outputs": [],
      "source": [
        "user_prompt_simple_french = \"\"\"\n",
        "Veuillez identifier et extraire les articles concernant le grave séisme de Messine en décembre 1908 ou ses conséquences dans le document de journal fourni. Si vous ne trouvez aucun article pertinent sur ce sujet, répondez simplement 'Aucun article pertinent trouvé.' Si vous trouvez un ou plusieurs articles, retournez leur contenu complet et inchangé (du début à la fin) au format XML, chaque article étant encadré par des balises <article>.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "user_prompt_simple_english = \"\"\"\n",
        "Please identify and extract articles that relate to the severe Messina earthquake in December 1908 or its aftermath in the provided newspaper document. If you don't find any relevant articles relating to this topic, simply return 'No relevant article found.' If you find one or more articles, return their full, unchanged content (beginning to end) structured in xml format, each wrapped in <article> tags.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSCgBf5B5MrK"
      },
      "outputs": [],
      "source": [
        "system_prompt2_english = \"\"\"\n",
        "You are an expert text analyst and information retrieval specialist and hate summarization as well as enumerations.\n",
        "Your task is to carefully analyze given texts and extract complete articles that contain specific themes only on the Messina earthquake 1908 and the direkt consequences of the earthquake (until march 1909) . You never change original texts.\n",
        "\n",
        "Classify as relevant if the text contains:\n",
        "- Primary earthquake terminology from the 19th and 20th century\n",
        "- Official earthquake reports\n",
        "- gelogy and seismology\n",
        "- Impact descriptions\n",
        "- Solution description\n",
        "- Technical description\n",
        "- Aid\n",
        "- Political discussion and opinions on earthquake\n",
        "- Stories from victims and refugees\n",
        "- reportings on refugees and victims\n",
        "- Live of victims\n",
        "- historical references\n",
        "- comparisons\n",
        "\n",
        "Your output should consist of nothing else but the the xml structure >article></article><verification></verification><human_verification_needed></human_verification_needed> or \"No relevant article found.\"\n",
        "\n",
        "Maintain a neutral, objective stance throughout the analysis. Focus on accuracy and completeness in your extractions\"\"\"\n",
        "\n",
        "user_prompt2_english = \"\"\"\n",
        "\n",
        "Please follow these specifications:\n",
        "1. Definition of an article: An article is a semantic unit in the text, clearly distinguished from preceding and following content (for example, may or may not have a title).\n",
        "2. Relevance criteria: An article is relevant if its main subject is the Messina earthquake of December 1908 or its consequences. Other earthquakes are not relevant. The relevant consequences are mentioned in the system prompt. Make sure to check the publication date.\n",
        "--> Keep international news sections together: Example Jena, January 8. The local geologist, Dr. Gravelitz, has established that the seabed of the Strait of Messina has become silted up in places following the earthquake. At some points, soundings show only fifteen feet of depth. Rome, January 9. General Mazza has telegraphed to the Prime Minister that it will be possible to recover all funds and archives of public services from the ruins of Reggio di Calabria. Railway communication between Reggio and Naples will be restored within three days.\n",
        "3. Response format:\n",
        "• If one or more relevant articles are found, structure your response using XML tags as shown in the following example, using the tags article, verification and human_verification_needed (True or False): <article>complete content of extracted article 1</article><article>complete content of extracted article 2</article><verification>Is the unit coherent? Is the subject present? Is the article complete? Have all articles been found?</verification><human_verification_needed>False</human_verification_needed>\n",
        "• Return all relevant articles in their original form, without additions, omissions, corrections or comments. Never cut content between the beginning and end of an article.\n",
        "• If no relevant articles about the Messina earthquake are found (for example, if it concerns another earthquake), no special structuring is needed; simply return \"No relevant article found.\" without further explanation.\n",
        "4. Notes on segmentation:\n",
        "• Ensure that articles form a unit. Be sure to mark each separate unit (marked by a new title or new semantic unit) as a new article <article></article>)\n",
        "5. Human verification needed:\n",
        "• Can have values \"True\" or \"False\"\n",
        "• False: If you think you have correctly segmented the article and evaluated its relevance.\n",
        "• True: If you are unsure whether you have captured the complete content of the article as contained in the newspaper document or if it is relevant.\n",
        "7. Check verification results and adapt response if necessary\n",
        "\n",
        "Here is the newspaper document:\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBjAbykYj38g"
      },
      "source": [
        "## Function for article extraction\n",
        "The function can be called using different model functions. It returns a list containing the separated articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMzK2k5pj0mz"
      },
      "outputs": [],
      "source": [
        "# function to separate articles\n",
        "def separate_articles_in_dataframe(df, text_column, model_function, user_prompt, **kwargs):\n",
        "\n",
        "    articles = []\n",
        "\n",
        "    i = 0\n",
        "    for index, row in df.iterrows():\n",
        "        i+=1\n",
        "        text = row[text_column]\n",
        "        article = model_function(text, user_prompt, **kwargs)  # call specific model function\n",
        "        articles.append(article)\n",
        "        print(f\"entry {i}/{len(df)} appended.\")\n",
        "\n",
        "\n",
        "    return articles\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqX6m6flkaiH"
      },
      "source": [
        "## GPT: Model function and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wqDQDyMCkbEn"
      },
      "outputs": [],
      "source": [
        "!pip install openai==1.55.3\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "client_openai = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "\n",
        "\n",
        "def call_openAI_api(text, user_prompt,system_prompt, model=\"gpt-4o-2024-08-06\", temperature=0.2, top_p=1, top_k=None, max_tokens=8000):\n",
        "    prompt = f\"{user_prompt} \\\\n\\n{text}\\n---\\n\"\n",
        "    messages = []\n",
        "\n",
        "    if system_prompt:\n",
        "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    try:\n",
        "        # Create a parameters dictionary\n",
        "        params = {\n",
        "            \"model\": model,\n",
        "            \"messages\": messages,\n",
        "            \"temperature\": temperature,\n",
        "            \"top_p\": top_p,\n",
        "            \"max_tokens\": max_tokens\n",
        "        }\n",
        "\n",
        "        # Add top_k only if it is not None\n",
        "        if top_k is not None:\n",
        "            params[\"top_k\"] = top_k\n",
        "\n",
        "        response = client_openai.chat.completions.create(**params)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Fehler beim Aufruf der openAI-API: {e}\")\n",
        "        return None\n",
        "\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model/Function for the Claude model (Anthropic)"
      ],
      "metadata": {
        "id": "MsWHYCHztv_Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EujAusmhzwx",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install anthropic\n",
        "from anthropic import Anthropic\n",
        "import os\n",
        "\n",
        "client = Anthropic(api_key=userdata.get('ANTHROPIC_API_KEY'))\n",
        "\n",
        "def call_claude_api(text, user_prompt, system_prompt=None, model=\"claude-3-5-sonnet-latest\", temperature=0.2, top_p=1, max_tokens=8000):\n",
        "   prompt = f\"{user_prompt}\\n\\n{text}\\n---\\n\"\n",
        "   messages = []\n",
        "\n",
        "   if system_prompt:\n",
        "       messages.append({\"role\": \"assistant\", \"content\": system_prompt})\n",
        "\n",
        "   messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "   try:\n",
        "       response = client.messages.create(\n",
        "           model=model,\n",
        "           messages=messages,\n",
        "           temperature=temperature,\n",
        "           top_p=top_p,\n",
        "           max_tokens=max_tokens\n",
        "       )\n",
        "       return response.content[0].text\n",
        "\n",
        "   except Exception as e:\n",
        "       print(f\"Error calling Claude API: {e}\")\n",
        "       return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deepseek function"
      ],
      "metadata": {
        "id": "yu8fTOjwt3w2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "294_hVSCCviD"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from typing import Optional, Dict, Any\n",
        "\n",
        "# Initialize the DeepSeek client with the correct API key and base URL\n",
        "client_deepseek = OpenAI(api_key=userdata.get('DEEPSEEK_API_KEY'), base_url=\"https://api.deepseek.com\")\n",
        "\n",
        "def call_deepseek_api(\n",
        "    text: str,\n",
        "    user_prompt: str,\n",
        "    model: str = \"deepseek-reasoner\",\n",
        "    system_prompt: Optional[str] = None,\n",
        "    temperature: float = 0.2,\n",
        "    top_p: float = 1,\n",
        "    top_k: Optional[int] = None,\n",
        "    max_tokens: int = 8000,\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Calls the DeepSeek API to generate a response based on the provided text and prompts.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to be processed.\n",
        "        user_prompt (str): The user's prompt or instruction.\n",
        "        model (str): The model to use for the API call.\n",
        "        system_prompt (Optional[str]): An optional system-level prompt.\n",
        "        temperature (float): Sampling temperature.\n",
        "        top_p (float): Nucleus sampling parameter.\n",
        "        top_k (Optional[int]): Top-k sampling parameter.\n",
        "        max_tokens (int): Maximum number of tokens to generate.\n",
        "\n",
        "    Returns:\n",
        "        Optional[str]: The generated response with reasoning in <think> tags, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    # Format the prompt to explicitly request reasoning\n",
        "    prompt = (\n",
        "        f\"Analyze the following and provide your reasoning in <think> tags, \"\n",
        "        f\"followed by your response:\\n\\n\"\n",
        "        f\"User Request: {user_prompt}\\n\"\n",
        "        f\"Text: {text}\\n---\\n\"\n",
        "    )\n",
        "    messages = []\n",
        "\n",
        "    # Add system prompt if provided\n",
        "    if system_prompt:\n",
        "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "\n",
        "    # Add user prompt\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    try:\n",
        "        # Create a parameters dictionary\n",
        "        params: Dict[str, Any] = {\n",
        "            \"model\": model,\n",
        "            \"messages\": messages,\n",
        "            \"temperature\": temperature,\n",
        "            \"top_p\": top_p,\n",
        "            \"max_tokens\": max_tokens,\n",
        "        }\n",
        "\n",
        "        if top_k is not None:\n",
        "            params[\"top_k\"] = top_k\n",
        "\n",
        "        # Call the DeepSeek API\n",
        "        response = client_deepseek.chat.completions.create(**params)\n",
        "\n",
        "        # Get the response content\n",
        "        content = response.choices[0].message.content\n",
        "\n",
        "        # Structure the response with think tags if not already present\n",
        "        if \"<think>\" not in content:\n",
        "            # Get the model's reasoning from the API response\n",
        "            reasoning = getattr(response.choices[0].message, 'reasoning_content', 'No explicit reasoning provided')\n",
        "            # Format the final response with think tags\n",
        "            formatted_response = f\"<think>{reasoning}</think>\\n\\n{content}\"\n",
        "            return formatted_response\n",
        "\n",
        "        return content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling the DeepSeek API: {e}\")\n",
        "        return None"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "goohfnYumfRi",
        "XX0QM9Z-pH9I"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}